<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebGPU Camera Test</title>
    <!-- ONNX Runtime WebGPU build -->
    <script src="onnx/ort.webgpu.min.js"></script>
    <style>
        body {
            margin: 0;
            padding: 20px;
            font-family: monospace;
            background: #1a1a1a;
            color: #00ff00;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
        }
        h1 {
            text-align: center;
            margin-bottom: 20px;
        }
        #videoContainer {
            position: relative;
            width: 640px;
            height: 480px;
            margin: 0 auto 20px;
            border: 2px solid #00ff00;
        }
        video, canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }
        #overlayCanvas {
            pointer-events: none;
        }
        #hiddenCanvas {
            display: none;
        }
        .controls {
            text-align: center;
            margin-bottom: 20px;
        }
        button {
            padding: 15px 30px;
            margin: 5px;
            font-size: 16px;
            font-family: monospace;
            font-weight: bold;
            cursor: pointer;
            border: none;
            background: #00ff00;
            color: #000;
        }
        button:disabled {
            background: #666;
            cursor: not-allowed;
        }
        button.stop {
            background: #ff0000;
        }
        .slider-container {
            background: #2a2a2a;
            border: 2px solid #00ff00;
            border-radius: 8px;
            padding: 15px;
            margin: 20px auto;
            max-width: 400px;
        }
        .slider-title {
            text-align: center;
            font-weight: bold;
            margin-bottom: 10px;
        }
        .slider-controls {
            display: flex;
            align-items: center;
            gap: 10px;
        }
        input[type="range"] {
            flex: 1;
            height: 6px;
        }
        .slider-value {
            text-align: center;
            font-size: 18px;
            font-weight: bold;
            margin-top: 10px;
        }
        .detection-count {
            text-align: center;
            font-size: 12px;
            color: #888;
            margin-top: 5px;
        }
        #status {
            text-align: center;
            margin-top: 20px;
            padding: 10px;
            background: #2a2a2a;
            border-radius: 5px;
        }
        .stats {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin-top: 10px;
            font-size: 14px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>WebGPU Camera Test</h1>
        
        <div id="videoContainer">
            <video id="video" autoplay playsinline muted></video>
            <canvas id="overlayCanvas"></canvas>
            <canvas id="hiddenCanvas"></canvas>
        </div>

        <div class="controls">
            <button id="runOnce" disabled>Run Once</button>
            <button id="autoMode" disabled>Start Auto</button>
            <button id="capture" disabled>Capture (0)</button>
        </div>

        <div class="slider-container">
            <div class="slider-title">Confidence Filter</div>
            <div class="slider-controls">
                <span>0%</span>
                <input type="range" id="threshold" min="0" max="1" step="0.05" value="0.7">
                <span>100%</span>
            </div>
            <div class="slider-value" id="thresholdValue">70%</div>
            <div class="detection-count" id="detectionCount">0 / 0 cards shown</div>
        </div>

        <div id="status">
            <div id="statusText">Initializing...</div>
            <div class="stats">
                <div>Inference: <span id="inferenceTime">--</span></div>
                <div>Provider: <span id="provider">--</span></div>
                <div>Detections: <span id="detectionTotal">0</span></div>
            </div>
        </div>
    </div>

    <script>
        // ============================================================================
        // LOGGING SYSTEM
        // ============================================================================
        const LogLevel = {
            DEBUG: 0,
            INFO: 1,
            WARNING: 2,
            ERROR: 3
        };

        class Logger {
            constructor(moduleName, minLevel = LogLevel.DEBUG) {
                this.moduleName = moduleName;
                this.minLevel = minLevel;
            }

            _log(level, functionName, message, data = null) {
                if (level < this.minLevel) return;

                const prefix = `[${this.moduleName}.${functionName}]`;
                const timestamp = new Date().toISOString().split('T')[1].split('.')[0];
                const fullMessage = `${timestamp} ${prefix} ${message}`;

                switch (level) {
                    case LogLevel.DEBUG:
                        console.log(`%c${fullMessage}`, 'color: #888', data || '');
                        break;
                    case LogLevel.INFO:
                        console.log(`%c${fullMessage}`, 'color: #00aaff', data || '');
                        break;
                    case LogLevel.WARNING:
                        console.warn(`${fullMessage}`, data || '');
                        break;
                    case LogLevel.ERROR:
                        console.error(`${fullMessage}`, data || '');
                        break;
                }
            }

            debug(functionName, message, data = null) {
                this._log(LogLevel.DEBUG, functionName, message, data);
            }

            info(functionName, message, data = null) {
                this._log(LogLevel.INFO, functionName, message, data);
            }

            warning(functionName, message, data = null) {
                this._log(LogLevel.WARNING, functionName, message, data);
            }

            error(functionName, message, data = null) {
                this._log(LogLevel.ERROR, functionName, message, data);
            }
        }

        // Create loggers for different modules
        const cameraLogger = new Logger('Camera');
        const modelLogger = new Logger('Model');
        const inferenceLogger = new Logger('Inference');
        const renderLogger = new Logger('Render');
        const uiLogger = new Logger('UI');
        const mainLogger = new Logger('Main');

        // ============================================================================
        // APPLICATION STATE
        // ============================================================================
        let session = null;
        let autoMode = false;
        let isProcessing = false;
        let detections = [];
        let confidenceThreshold = 0.7;
        let animationFrameId = null;

        const video = document.getElementById('video');
        const overlayCanvas = document.getElementById('overlayCanvas');
        const hiddenCanvas = document.getElementById('hiddenCanvas');
        const overlayCtx = overlayCanvas.getContext('2d');
        const hiddenCtx = hiddenCanvas.getContext('2d', { willReadFrequently: true });

        const statusText = document.getElementById('statusText');
        const inferenceTimeEl = document.getElementById('inferenceTime');
        const providerEl = document.getElementById('provider');
        const detectionTotalEl = document.getElementById('detectionTotal');
        const thresholdValueEl = document.getElementById('thresholdValue');
        const detectionCountEl = document.getElementById('detectionCount');

        const runOnceBtn = document.getElementById('runOnce');
        const autoModeBtn = document.getElementById('autoMode');
        const captureBtn = document.getElementById('capture');
        const thresholdInput = document.getElementById('threshold');

        // ============================================================================
        // CAMERA INITIALIZATION
        // ============================================================================
        async function initCamera() {
            cameraLogger.info('initCamera', 'Starting camera initialization');
            try {
                statusText.textContent = 'Requesting camera access...';
                cameraLogger.debug('initCamera', 'Requesting camera permissions with constraints', {
                    facingMode: 'environment',
                    width: 1920,
                    height: 1080
                });
                
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        facingMode: 'environment',
                        width: { ideal: 1920 },
                        height: { ideal: 1080 }
                    }
                });
                
                cameraLogger.info('initCamera', 'Camera access granted');
                video.srcObject = stream;
                
                video.onloadedmetadata = () => {
                    const videoInfo = {
                        clientWidth: video.clientWidth,
                        clientHeight: video.clientHeight,
                        videoWidth: video.videoWidth,
                        videoHeight: video.videoHeight
                    };
                    cameraLogger.info('initCamera', 'Video metadata loaded', videoInfo);
                    
                    overlayCanvas.width = video.clientWidth;
                    overlayCanvas.height = video.clientHeight;
                    statusText.textContent = 'Camera ready';
                    
                    cameraLogger.info('initCamera', 'Camera initialization complete');
                };
            } catch (error) {
                cameraLogger.error('initCamera', `Failed to initialize camera: ${error.message}`, error);
                statusText.textContent = `Camera error: ${error.message}`;
            }
        }

        // ============================================================================
        // MODEL LOADING
        // ============================================================================
        async function loadModel() {
            modelLogger.info('loadModel', 'Starting model loading');
            
            if (!window.ort) {
                modelLogger.error('loadModel', 'ONNX Runtime not available in window object');
                statusText.textContent = 'Error: ONNX Runtime not loaded';
                return;
            }

            modelLogger.debug('loadModel', `ONNX Runtime version: ${ort.env.versions.common}`);

            try {
                statusText.textContent = 'Loading model...';
                modelLogger.info('loadModel', 'Creating inference session with WebGPU (no fallback)');

                const startTime = performance.now();
                session = await ort.InferenceSession.create('/models/trading_card_detector.onnx', {
                    executionProviders: ['webgpu'],
                    graphOptimizationLevel: 'all'
                });

                const loadTime = performance.now() - startTime;
                modelLogger.info('loadModel', `Model loaded successfully in ${loadTime.toFixed(2)}ms`);
                
                // Log model details
                const modelInfo = {
                    inputNames: session.inputNames,
                    outputNames: session.outputNames,
                    inputTypes: session.inputNames.map(name => {
                        const input = session._model?.graph?.input?.find(i => i.name === name);
                        return input?.type?.tensorType?.elemType || 'unknown';
                    })
                };
                modelLogger.debug('loadModel', 'Model metadata', modelInfo);
                
                statusText.textContent = 'Model ready - Click Start Auto or Run Once';
                providerEl.textContent = 'WebGPU';
                
                runOnceBtn.disabled = false;
                autoModeBtn.disabled = false;
                
                modelLogger.info('loadModel', 'Model initialization complete');
            } catch (error) {
                modelLogger.error('loadModel', `Failed to load model: ${error.message}`, {
                    error: error,
                    stack: error.stack
                });
                statusText.textContent = `Model load error: ${error.message}`;
            }
        }

        // ============================================================================
        // IMAGE PREPROCESSING
        // ============================================================================
        function preprocessImage(imageData) {
            inferenceLogger.debug('preprocessImage', `Starting preprocessing of ${imageData.width}x${imageData.height} image`);
            
            const { width, height } = imageData;
            const targetSize = 1088;

            const scale = Math.min(targetSize / width, targetSize / height);
            const newW = Math.round(width * scale);
            const newH = Math.round(height * scale);
            const padX = Math.floor((targetSize - newW) / 2);
            const padY = Math.floor((targetSize - newH) / 2);

            inferenceLogger.debug('preprocessImage', 'Scaling parameters', {
                originalSize: `${width}x${height}`,
                targetSize: targetSize,
                scale: scale.toFixed(3),
                scaledSize: `${newW}x${newH}`,
                padding: `${padX}x${padY}`
            });

            // Create source canvas from ImageData
            const srcCanvas = document.createElement('canvas');
            const srcCtx = srcCanvas.getContext('2d');
            srcCanvas.width = width;
            srcCanvas.height = height;
            srcCtx.putImageData(imageData, 0, 0);

            // Create target canvas with padding
            const dstCanvas = document.createElement('canvas');
            const dstCtx = dstCanvas.getContext('2d');
            dstCanvas.width = targetSize;
            dstCanvas.height = targetSize;

            // Fill with gray padding
            dstCtx.fillStyle = '#808080';
            dstCtx.fillRect(0, 0, targetSize, targetSize);
            dstCtx.drawImage(srcCanvas, 0, 0, width, height, padX, padY, newW, newH);

            // Convert to tensor
            const resized = dstCtx.getImageData(0, 0, targetSize, targetSize);
            const pixels = resized.data;
            const tensorData = new Float32Array(1 * 3 * targetSize * targetSize);
            const pixelCount = targetSize * targetSize;

            inferenceLogger.debug('preprocessImage', 'Converting to tensor (CHW format)');
            for (let i = 0; i < pixelCount; i++) {
                const p = i * 4;
                tensorData[i] = pixels[p] / 255.0;
                tensorData[i + pixelCount] = pixels[p + 1] / 255.0;
                tensorData[i + 2 * pixelCount] = pixels[p + 2] / 255.0;
            }

            const tensor = new ort.Tensor('float32', tensorData, [1, 3, targetSize, targetSize]);
            inferenceLogger.debug('preprocessImage', `Tensor created: ${tensor.dims.join('x')}, type: ${tensor.type}`);
            
            return tensor;
        }

        // ============================================================================
        // INFERENCE
        // ============================================================================
        async function runInference() {
            if (!session) {
                inferenceLogger.warning('runInference', 'No session available, skipping inference');
                return;
            }
            
            if (isProcessing) {
                inferenceLogger.debug('runInference', 'Already processing, skipping this frame');
                return;
            }

            inferenceLogger.info('runInference', 'Starting inference');

            try {
                isProcessing = true;

                // Capture video frame
                hiddenCanvas.width = video.videoWidth;
                hiddenCanvas.height = video.videoHeight;
                hiddenCtx.drawImage(video, 0, 0);
                inferenceLogger.debug('runInference', `Captured frame: ${video.videoWidth}x${video.videoHeight}`);

                const imageData = hiddenCtx.getImageData(0, 0, hiddenCanvas.width, hiddenCanvas.height);
                const inputTensor = preprocessImage(imageData);

                // Run model inference
                inferenceLogger.debug('runInference', 'Running model with input', {
                    inputName: session.inputNames[0],
                    inputShape: inputTensor.dims.join('x')
                });
                
                const inferenceStart = performance.now();
                const results = await session.run({
                    [session.inputNames[0]]: inputTensor
                });
                const inferenceMs = performance.now() - inferenceStart;

                inferenceLogger.info('runInference', `Inference completed in ${inferenceMs.toFixed(1)}ms`);
                inferenceTimeEl.textContent = `${inferenceMs.toFixed(0)}ms`;
                providerEl.textContent = 'WebGPU';

                // Validate outputs
                inferenceLogger.debug('runInference', 'Model outputs', {
                    expectedOutputs: session.outputNames,
                    actualOutputs: Object.keys(results),
                    outputCount: session.outputNames.length
                });

                // Log detailed output information
                session.outputNames.forEach((name, idx) => {
                    if (results[name]) {
                        inferenceLogger.debug('runInference', `Output ${idx}: ${name}`, {
                            shape: results[name].dims.join('x'),
                            type: results[name].type,
                            dataLength: results[name].data.length,
                            firstFewValues: Array.from(results[name].data.slice(0, 10))
                        });
                    }
                });

                // Parse output based on structure
                const output = results[session.outputNames[0]];
                const outputData = output.data;
                const outputShape = output.dims;
                
                inferenceLogger.debug('runInference', 'Parsing output', {
                    shape: outputShape.join('x'),
                    format: 'OBB (Oriented Bounding Boxes)',
                    valuesPerDetection: outputShape[2]
                });

                // Parse OBB format: [batch, num_detections, 7]
                // Each detection: [x_center, y_center, width, height, confidence, class_id, angle]
                const numDetections = outputShape[1];
                const valuesPerDetection = outputShape[2];
                
                if (valuesPerDetection !== 7) {
                    inferenceLogger.warning('runInference', `Expected 7 values per detection, got ${valuesPerDetection}`);
                }

                // Process detections
                detections = [];
                const minConfidence = 0.3;
                
                for (let i = 0; i < numDetections; i++) {
                    const offset = i * valuesPerDetection;
                    const x = outputData[offset];
                    const y = outputData[offset + 1];
                    const w = outputData[offset + 2];
                    const h = outputData[offset + 3];
                    const confidence = outputData[offset + 4];
                    const classId = outputData[offset + 5];
                    const angle = outputData[offset + 6];
                    
                    if (confidence >= minConfidence) {
                        // Normalize coordinates (assuming they're in pixel space of 1088x1088)
                        const normalizedX = x / 1088;
                        const normalizedY = y / 1088;
                        const normalizedW = w / 1088;
                        const normalizedH = h / 1088;
                        
                        detections.push({
                            x: normalizedX,
                            y: normalizedY,
                            width: normalizedW,
                            height: normalizedH,
                            confidence: confidence,
                            classId: classId,
                            angle: angle
                        });
                    }
                }

                inferenceLogger.info('runInference', `Found ${detections.length} detections (threshold: 0.3)`);
                
                if (detections.length > 0) {
                    const confidences = detections.map(d => d.confidence.toFixed(3));
                    inferenceLogger.debug('runInference', 'Detection confidences', { confidences });
                }

                drawDetections();
                updateStats();

            } catch (error) {
                inferenceLogger.error('runInference', `Inference failed: ${error.message}`, {
                    error: error,
                    stack: error.stack
                });
                statusText.textContent = `Error: ${error.message}`;
            } finally {
                isProcessing = false;
                inferenceLogger.debug('runInference', 'Inference complete, released processing lock');
            }
        }

        // ============================================================================
        // RENDERING
        // ============================================================================
        function drawDetections() {
            renderLogger.debug('drawDetections', `Drawing ${detections.length} detections`);
            
            overlayCanvas.width = video.clientWidth;
            overlayCanvas.height = video.clientHeight;
            overlayCtx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);

            const filtered = detections.filter(d => d.confidence >= confidenceThreshold);
            renderLogger.debug('drawDetections', `${filtered.length} detections pass threshold ${confidenceThreshold}`);

            filtered.forEach((det, idx) => {
                // Convert normalized coordinates to canvas pixels
                const centerX = det.x * overlayCanvas.width;
                const centerY = det.y * overlayCanvas.height;
                const w = det.width * overlayCanvas.width;
                const h = det.height * overlayCanvas.height;
                const angle = det.angle || 0;

                overlayCtx.save();
                
                // Move to center of box and rotate
                overlayCtx.translate(centerX, centerY);
                overlayCtx.rotate(angle);
                
                // Draw rotated rectangle (centered at origin after translate)
                overlayCtx.strokeStyle = '#00ff00';
                overlayCtx.lineWidth = 3;
                overlayCtx.strokeRect(-w/2, -h/2, w, h);
                
                // Draw confidence label (unrotated for readability)
                overlayCtx.rotate(-angle);
                overlayCtx.fillStyle = '#00ff00';
                overlayCtx.font = '16px monospace';
                const label = `${(det.confidence * 100).toFixed(0)}%`;
                overlayCtx.fillText(label, -w/2, -h/2 - 5);
                
                overlayCtx.restore();
            });
            
            if (filtered.length > 0) {
                renderLogger.debug('drawDetections', `Rendered ${filtered.length} oriented bounding boxes`);
            }
        }

        // ============================================================================
        // UI UPDATES
        // ============================================================================
        function updateStats() {
            const filtered = detections.filter(d => d.confidence >= confidenceThreshold);
            detectionTotalEl.textContent = detections.length;
            detectionCountEl.textContent = `${filtered.length} / ${detections.length} cards shown`;
            captureBtn.textContent = `Capture (${filtered.length})`;
            captureBtn.disabled = filtered.length === 0;
            
            uiLogger.debug('updateStats', `Stats updated: ${filtered.length}/${detections.length} shown`);
        }

        // ============================================================================
        // AUTO MODE LOOP
        // ============================================================================
        function autoModeLoop() {
            if (!autoMode || isProcessing) {
                animationFrameId = requestAnimationFrame(autoModeLoop);
                return;
            }
            
            runInference().then(() => {
                if (autoMode) {
                    animationFrameId = requestAnimationFrame(autoModeLoop);
                }
            });
        }

        // ============================================================================
        // EVENT HANDLERS
        // ============================================================================
        runOnceBtn.addEventListener('click', () => {
            uiLogger.info('runOnceBtn.click', 'User clicked Run Once');
            runInference();
        });

        autoModeBtn.addEventListener('click', () => {
            autoMode = !autoMode;
            if (autoMode) {
                uiLogger.info('autoModeBtn.click', 'Starting auto mode');
                autoModeBtn.textContent = 'Stop Auto';
                autoModeBtn.classList.add('stop');
                runOnceBtn.disabled = true;
                autoModeLoop();
            } else {
                uiLogger.info('autoModeBtn.click', 'Stopping auto mode');
                autoModeBtn.textContent = 'Start Auto';
                autoModeBtn.classList.remove('stop');
                runOnceBtn.disabled = false;
                if (animationFrameId) {
                    cancelAnimationFrame(animationFrameId);
                    animationFrameId = null;
                }
            }
        });

        captureBtn.addEventListener('click', () => {
            const filtered = detections.filter(d => d.confidence >= confidenceThreshold);
            uiLogger.info('captureBtn.click', `User clicked capture with ${filtered.length} detections`);
            alert(`Would capture ${filtered.length} cards (not implemented in test page)`);
        });

        thresholdInput.addEventListener('input', (e) => {
            const oldThreshold = confidenceThreshold;
            confidenceThreshold = parseFloat(e.target.value);
            uiLogger.debug('thresholdInput.input', `Threshold changed: ${oldThreshold.toFixed(2)} -> ${confidenceThreshold.toFixed(2)}`);
            
            thresholdValueEl.textContent = `${(confidenceThreshold * 100).toFixed(0)}%`;
            drawDetections();
            updateStats();
        });

        // ============================================================================
        // INITIALIZATION
        // ============================================================================
        mainLogger.info('init', 'Application starting');
        mainLogger.debug('init', 'User agent', { userAgent: navigator.userAgent });
        mainLogger.debug('init', 'WebGPU support', { 
            hasGPU: 'gpu' in navigator,
            hasWebGPU: typeof navigator.gpu !== 'undefined'
        });
        
        initCamera();
        loadModel();
    </script>
</body>
</html>

