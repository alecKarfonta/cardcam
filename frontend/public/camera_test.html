<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebGPU Camera Test</title>
    <!-- ONNX Runtime WebGPU build -->
    <script src="onnx/ort.webgpu.min.js"></script>
    <style>
        body {
            margin: 0;
            padding: 20px;
            font-family: monospace;
            background: #1a1a1a;
            color: #00ff00;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
        }
        h1 {
            text-align: center;
            margin-bottom: 20px;
        }
        #videoContainer {
            position: relative;
            width: 640px;
            height: 480px;
            margin: 0 auto 20px;
            border: 2px solid #00ff00;
        }
        video, canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }
        #overlayCanvas {
            pointer-events: none;
        }
        #hiddenCanvas {
            display: none;
        }
        .controls {
            text-align: center;
            margin-bottom: 20px;
        }
        button {
            padding: 15px 30px;
            margin: 5px;
            font-size: 16px;
            font-family: monospace;
            font-weight: bold;
            cursor: pointer;
            border: none;
            background: #00ff00;
            color: #000;
        }
        button:disabled {
            background: #666;
            cursor: not-allowed;
        }
        button.stop {
            background: #ff0000;
        }
        .slider-container {
            background: #2a2a2a;
            border: 2px solid #00ff00;
            border-radius: 8px;
            padding: 15px;
            margin: 20px auto;
            max-width: 400px;
        }
        .slider-title {
            text-align: center;
            font-weight: bold;
            margin-bottom: 10px;
        }
        .slider-controls {
            display: flex;
            align-items: center;
            gap: 10px;
        }
        input[type="range"] {
            flex: 1;
            height: 6px;
        }
        .slider-value {
            text-align: center;
            font-size: 18px;
            font-weight: bold;
            margin-top: 10px;
        }
        .detection-count {
            text-align: center;
            font-size: 12px;
            color: #888;
            margin-top: 5px;
        }
        #status {
            text-align: center;
            margin-top: 20px;
            padding: 10px;
            background: #2a2a2a;
            border-radius: 5px;
        }
        .stats {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin-top: 10px;
            font-size: 14px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>WebGPU Camera Test</h1>
        
        <div id="videoContainer">
            <video id="video" autoplay playsinline muted></video>
            <canvas id="overlayCanvas"></canvas>
            <canvas id="hiddenCanvas"></canvas>
        </div>

        <div class="controls">
            <button id="runOnce" disabled>Run Once</button>
            <button id="autoMode" disabled>Start Auto</button>
            <button id="capture" disabled>Capture (0)</button>
        </div>

        <div class="slider-container">
            <div class="slider-title">Confidence Filter</div>
            <div class="slider-controls">
                <span>0%</span>
                <input type="range" id="threshold" min="0" max="1" step="0.05" value="0.7">
                <span>100%</span>
            </div>
            <div class="slider-value" id="thresholdValue">70%</div>
            <div class="detection-count" id="detectionCount">0 / 0 cards shown</div>
        </div>

        <div id="status">
            <div id="statusText">Initializing...</div>
            <div class="stats">
                <div>Inference: <span id="inferenceTime">--</span></div>
                <div>Provider: <span id="provider">--</span></div>
                <div>Detections: <span id="detectionTotal">0</span></div>
            </div>
        </div>
    </div>

    <script>
        let session = null;
        let autoMode = false;
        let isProcessing = false;
        let detections = [];
        let confidenceThreshold = 0.7;
        let animationFrameId = null;

        const video = document.getElementById('video');
        const overlayCanvas = document.getElementById('overlayCanvas');
        const hiddenCanvas = document.getElementById('hiddenCanvas');
        const overlayCtx = overlayCanvas.getContext('2d');
        const hiddenCtx = hiddenCanvas.getContext('2d', { willReadFrequently: true });

        const statusText = document.getElementById('statusText');
        const inferenceTimeEl = document.getElementById('inferenceTime');
        const providerEl = document.getElementById('provider');
        const detectionTotalEl = document.getElementById('detectionTotal');
        const thresholdValueEl = document.getElementById('thresholdValue');
        const detectionCountEl = document.getElementById('detectionCount');

        const runOnceBtn = document.getElementById('runOnce');
        const autoModeBtn = document.getElementById('autoMode');
        const captureBtn = document.getElementById('capture');
        const thresholdInput = document.getElementById('threshold');

        // Initialize camera
        async function initCamera() {
            try {
                statusText.textContent = 'Requesting camera access...';
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        facingMode: 'environment',
                        width: { ideal: 1920 },
                        height: { ideal: 1080 }
                    }
                });
                video.srcObject = stream;
                
                video.onloadedmetadata = () => {
                    overlayCanvas.width = video.clientWidth;
                    overlayCanvas.height = video.clientHeight;
                    statusText.textContent = 'Camera ready';
                };
            } catch (error) {
                statusText.textContent = `Camera error: ${error.message}`;
                console.error('Camera error:', error);
            }
        }

        // Load model
        async function loadModel() {
            if (!window.ort) {
                statusText.textContent = 'Error: ONNX Runtime not loaded';
                return;
            }

            try {
                statusText.textContent = 'Loading model...';
                console.log('Loading model with WebGPU...');

                const startTime = performance.now();
                session = await ort.InferenceSession.create('/models/trading_card_detector.onnx', {
                    executionProviders: ['webgpu', 'wasm'],
                    graphOptimizationLevel: 'all'
                });

                const loadTime = performance.now() - startTime;
                console.log(`Model loaded in ${loadTime.toFixed(2)}ms`);
                
                statusText.textContent = 'Model ready - Click Start Auto or Run Once';
                providerEl.textContent = 'WebGPU/WASM';
                
                runOnceBtn.disabled = false;
                autoModeBtn.disabled = false;
            } catch (error) {
                statusText.textContent = `Model load error: ${error.message}`;
                console.error('Model load error:', error);
            }
        }

        // Preprocess image
        function preprocessImage(imageData) {
            const { width, height } = imageData;
            const targetSize = 1088;

            const scale = Math.min(targetSize / width, targetSize / height);
            const newW = Math.round(width * scale);
            const newH = Math.round(height * scale);
            const padX = Math.floor((targetSize - newW) / 2);
            const padY = Math.floor((targetSize - newH) / 2);

            const srcCanvas = document.createElement('canvas');
            const srcCtx = srcCanvas.getContext('2d');
            srcCanvas.width = width;
            srcCanvas.height = height;
            srcCtx.putImageData(imageData, 0, 0);

            const dstCanvas = document.createElement('canvas');
            const dstCtx = dstCanvas.getContext('2d');
            dstCanvas.width = targetSize;
            dstCanvas.height = targetSize;

            dstCtx.fillStyle = '#808080';
            dstCtx.fillRect(0, 0, targetSize, targetSize);
            dstCtx.drawImage(srcCanvas, 0, 0, width, height, padX, padY, newW, newH);

            const resized = dstCtx.getImageData(0, 0, targetSize, targetSize);
            const pixels = resized.data;
            const tensorData = new Float32Array(1 * 3 * targetSize * targetSize);
            const pixelCount = targetSize * targetSize;

            for (let i = 0; i < pixelCount; i++) {
                const p = i * 4;
                tensorData[i] = pixels[p] / 255.0;
                tensorData[i + pixelCount] = pixels[p + 1] / 255.0;
                tensorData[i + 2 * pixelCount] = pixels[p + 2] / 255.0;
            }

            return new ort.Tensor('float32', tensorData, [1, 3, targetSize, targetSize]);
        }

        // Run inference
        async function runInference() {
            if (!session || isProcessing) return;

            try {
                isProcessing = true;

                hiddenCanvas.width = video.videoWidth;
                hiddenCanvas.height = video.videoHeight;
                hiddenCtx.drawImage(video, 0, 0);

                const imageData = hiddenCtx.getImageData(0, 0, hiddenCanvas.width, hiddenCanvas.height);
                const inputTensor = preprocessImage(imageData);

                const inferenceStart = performance.now();
                const results = await session.run({
                    [session.inputNames[0]]: inputTensor
                });
                const inferenceMs = performance.now() - inferenceStart;

                inferenceTimeEl.textContent = `${inferenceMs.toFixed(0)}ms`;
                if (inferenceMs < 250) {
                    providerEl.textContent = 'ðŸš€ WebGPU';
                } else {
                    providerEl.textContent = 'WASM';
                }

                const boxes = results[session.outputNames[0]].data;
                const scores = results[session.outputNames[1]].data;

                detections = [];
                for (let i = 0; i < scores.length; i++) {
                    if (scores[i] >= 0.3) {
                        const x = boxes[i * 4];
                        const y = boxes[i * 4 + 1];
                        const w = boxes[i * 4 + 2] - x;
                        const h = boxes[i * 4 + 3] - y;
                        detections.push({ x, y, width: w, height: h, confidence: scores[i] });
                    }
                }

                drawDetections();
                updateStats();

            } catch (error) {
                console.error('Inference error:', error);
                statusText.textContent = `Error: ${error.message}`;
            } finally {
                isProcessing = false;
            }
        }

        // Draw detections
        function drawDetections() {
            overlayCanvas.width = video.clientWidth;
            overlayCanvas.height = video.clientHeight;
            overlayCtx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);

            const filtered = detections.filter(d => d.confidence >= confidenceThreshold);

            filtered.forEach(det => {
                const x = det.x * overlayCanvas.width;
                const y = det.y * overlayCanvas.height;
                const w = det.width * overlayCanvas.width;
                const h = det.height * overlayCanvas.height;

                overlayCtx.strokeStyle = '#00ff00';
                overlayCtx.lineWidth = 3;
                overlayCtx.strokeRect(x, y, w, h);

                overlayCtx.fillStyle = '#00ff00';
                overlayCtx.font = '16px monospace';
                overlayCtx.fillText(`${(det.confidence * 100).toFixed(0)}%`, x, y - 5);
            });
        }

        // Update stats
        function updateStats() {
            const filtered = detections.filter(d => d.confidence >= confidenceThreshold);
            detectionTotalEl.textContent = detections.length;
            detectionCountEl.textContent = `${filtered.length} / ${detections.length} cards shown`;
            captureBtn.textContent = `Capture (${filtered.length})`;
            captureBtn.disabled = filtered.length === 0;
        }

        // Auto mode loop
        function autoModeLoop() {
            if (!autoMode || isProcessing) {
                animationFrameId = requestAnimationFrame(autoModeLoop);
                return;
            }
            
            runInference().then(() => {
                if (autoMode) {
                    animationFrameId = requestAnimationFrame(autoModeLoop);
                }
            });
        }

        // Event listeners
        runOnceBtn.addEventListener('click', runInference);

        autoModeBtn.addEventListener('click', () => {
            autoMode = !autoMode;
            if (autoMode) {
                autoModeBtn.textContent = 'Stop Auto';
                autoModeBtn.classList.add('stop');
                runOnceBtn.disabled = true;
                autoModeLoop();
            } else {
                autoModeBtn.textContent = 'Start Auto';
                autoModeBtn.classList.remove('stop');
                runOnceBtn.disabled = false;
                if (animationFrameId) {
                    cancelAnimationFrame(animationFrameId);
                    animationFrameId = null;
                }
            }
        });

        captureBtn.addEventListener('click', () => {
            const filtered = detections.filter(d => d.confidence >= confidenceThreshold);
            alert(`Would capture ${filtered.length} cards (not implemented in test page)`);
        });

        thresholdInput.addEventListener('input', (e) => {
            confidenceThreshold = parseFloat(e.target.value);
            thresholdValueEl.textContent = `${(confidenceThreshold * 100).toFixed(0)}%`;
            drawDetections();
            updateStats();
        });

        // Initialize
        initCamera();
        loadModel();
    </script>
</body>
</html>

