<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebGPU Camera Test</title>
    <!-- ONNX Runtime WebGPU build -->
    <script src="onnx/ort.webgpu.min.js"></script>
    <!-- ByteTrack object tracking -->
    <script src="bytetrack.js"></script>
    <style>
        body {
            margin: 0;
            padding: 20px;
            font-family: monospace;
            background: #1a1a1a;
            color: #00ff00;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
        }
        h1 {
            text-align: center;
            margin-bottom: 20px;
        }
        #videoContainer {
            position: relative;
            width: 640px;
            height: 480px;
            margin: 0 auto 20px;
            border: 2px solid #00ff00;
        }
        video, canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }
        #overlayCanvas {
            pointer-events: none;
        }
        #hiddenCanvas {
            display: none;
        }
        .controls {
            text-align: center;
            margin-bottom: 20px;
        }
        button {
            padding: 15px 30px;
            margin: 5px;
            font-size: 16px;
            font-family: monospace;
            font-weight: bold;
            cursor: pointer;
            border: none;
            background: #00ff00;
            color: #000;
        }
        button:disabled {
            background: #666;
            cursor: not-allowed;
        }
        button.stop {
            background: #ff0000;
        }
        .slider-container {
            background: #2a2a2a;
            border: 2px solid #00ff00;
            border-radius: 8px;
            padding: 15px;
            margin: 20px auto;
            max-width: 400px;
        }
        .slider-title {
            text-align: center;
            font-weight: bold;
            margin-bottom: 10px;
        }
        .slider-controls {
            display: flex;
            align-items: center;
            gap: 10px;
        }
        input[type="range"] {
            flex: 1;
            height: 6px;
        }
        .slider-value {
            text-align: center;
            font-size: 18px;
            font-weight: bold;
            margin-top: 10px;
        }
        .detection-count {
            text-align: center;
            font-size: 12px;
            color: #888;
            margin-top: 5px;
        }
        #status {
            text-align: center;
            margin-top: 20px;
            padding: 10px;
            background: #2a2a2a;
            border-radius: 5px;
        }
        .stats {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin-top: 10px;
            font-size: 14px;
        }
        .tracking-params {
            background: #2a2a2a;
            border: 2px solid #00ff00;
            border-radius: 8px;
            padding: 15px;
            margin: 20px auto;
            max-width: 600px;
            display: none;
        }
        .tracking-params.visible {
            display: block;
        }
        .tracking-params h3 {
            text-align: center;
            margin-top: 0;
            margin-bottom: 15px;
            font-size: 18px;
        }
        .param-group {
            margin-bottom: 15px;
            padding-bottom: 15px;
            border-bottom: 1px solid #444;
        }
        .param-group:last-child {
            border-bottom: none;
            margin-bottom: 0;
            padding-bottom: 0;
        }
        .param-label {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 5px;
            font-weight: bold;
        }
        .param-value {
            color: #00ff00;
            font-size: 16px;
        }
        .param-description {
            font-size: 11px;
            color: #888;
            margin-bottom: 8px;
            line-height: 1.4;
        }
        .param-slider {
            width: 100%;
            height: 6px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>WebGPU Camera Test</h1>
        
        <div id="videoContainer">
            <video id="video" autoplay playsinline muted></video>
            <canvas id="overlayCanvas"></canvas>
            <canvas id="hiddenCanvas"></canvas>
        </div>

        <div class="controls">
            <button id="runOnce" disabled>Run Once</button>
            <button id="autoMode" disabled>Start Auto</button>
            <button id="capture" disabled>Capture (0)</button>
            <button id="downloadTraining" disabled>Download Training Data</button>
        </div>

        <div class="controls" style="margin-top: 10px;">
            <label style="cursor: pointer; margin-right: 20px;">
                <input type="checkbox" id="includeOverlay" checked>
                Include visualization with bounding boxes
            </label>
            <label style="cursor: pointer;">
                <input type="checkbox" id="enableTracking">
                Enable Object Tracking (ByteTrack)
            </label>
        </div>

        <div class="slider-container">
            <div class="slider-title">Confidence Filter</div>
            <div class="slider-controls">
                <span>0%</span>
                <input type="range" id="threshold" min="0" max="1" step="0.05" value="0.7">
                <span>100%</span>
            </div>
            <div class="slider-value" id="thresholdValue">70%</div>
            <div class="detection-count" id="detectionCount">0 / 0 cards shown</div>
        </div>

        <div class="tracking-params" id="trackingParams">
            <h3>ByteTrack Parameters</h3>
            
            <div class="param-group">
                <div class="param-label">
                    <span>High Confidence Threshold</span>
                    <span class="param-value" id="trackHighThreshValue">60%</span>
                </div>
                <div class="param-description">
                    Detections above this confidence are prioritized for first-stage matching. Higher values = more selective.
                </div>
                <input type="range" class="param-slider" id="trackHighThresh" min="0.3" max="0.95" step="0.05" value="0.6">
            </div>

            <div class="param-group">
                <div class="param-label">
                    <span>Low Confidence Threshold</span>
                    <span class="param-value" id="trackLowThreshValue">30%</span>
                </div>
                <div class="param-description">
                    Minimum confidence for second-stage matching. Helps recover temporarily low-confidence detections of existing tracks.
                </div>
                <input type="range" class="param-slider" id="trackLowThresh" min="0.1" max="0.6" step="0.05" value="0.3">
            </div>

            <div class="param-group">
                <div class="param-label">
                    <span>New Track Threshold</span>
                    <span class="param-value" id="newTrackThreshValue">70%</span>
                </div>
                <div class="param-description">
                    Minimum confidence required to start tracking a new object. Higher values prevent false positives from creating tracks.
                </div>
                <input type="range" class="param-slider" id="newTrackThresh" min="0.4" max="0.95" step="0.05" value="0.7">
            </div>

            <div class="param-group">
                <div class="param-label">
                    <span>Match Threshold (IoU)</span>
                    <span class="param-value" id="matchThreshValue">0.80</span>
                </div>
                <div class="param-description">
                    Minimum Intersection-over-Union to match a detection to an existing track. Higher values = stricter matching (0.0-1.0).
                </div>
                <input type="range" class="param-slider" id="matchThresh" min="0.3" max="0.95" step="0.05" value="0.8">
            </div>

            <div class="param-group">
                <div class="param-label">
                    <span>Max Age (frames)</span>
                    <span class="param-value" id="maxAgeValue">30</span>
                </div>
                <div class="param-description">
                    Number of frames a track can persist without a matched detection before being deleted. Higher = more tolerant of occlusion.
                </div>
                <input type="range" class="param-slider" id="maxAge" min="5" max="60" step="5" value="30">
            </div>

            <div class="param-group">
                <div class="param-label">
                    <span>Minimum Hits</span>
                    <span class="param-value" id="minHitsValue">3</span>
                </div>
                <div class="param-description">
                    Number of consecutive detections required before a track is confirmed and displayed. Higher = fewer false positives.
                </div>
                <input type="range" class="param-slider" id="minHits" min="1" max="10" step="1" value="3">
            </div>
        </div>

        <div id="status">
            <div id="statusText">Initializing...</div>
            <div class="stats">
                <div>Inference: <span id="inferenceTime">--</span></div>
                <div>Provider: <span id="provider">--</span></div>
                <div>Detections: <span id="detectionTotal">0</span></div>
            </div>
        </div>
    </div>

    <script>
        // ============================================================================
        // LOGGING SYSTEM
        // ============================================================================
        const LogLevel = {
            DEBUG: 0,
            INFO: 1,
            WARNING: 2,
            ERROR: 3
        };

        class Logger {
            constructor(moduleName, minLevel = LogLevel.DEBUG) {
                this.moduleName = moduleName;
                this.minLevel = minLevel;
            }

            _log(level, functionName, message, data = null) {
                if (level < this.minLevel) return;

                const prefix = `[${this.moduleName}.${functionName}]`;
                const timestamp = new Date().toISOString().split('T')[1].split('.')[0];
                const fullMessage = `${timestamp} ${prefix} ${message}`;

                switch (level) {
                    case LogLevel.DEBUG:
                        console.log(`%c${fullMessage}`, 'color: #888', data || '');
                        break;
                    case LogLevel.INFO:
                        console.log(`%c${fullMessage}`, 'color: #00aaff', data || '');
                        break;
                    case LogLevel.WARNING:
                        console.warn(`${fullMessage}`, data || '');
                        break;
                    case LogLevel.ERROR:
                        console.error(`${fullMessage}`, data || '');
                        break;
                }
            }

            debug(functionName, message, data = null) {
                this._log(LogLevel.DEBUG, functionName, message, data);
            }

            info(functionName, message, data = null) {
                this._log(LogLevel.INFO, functionName, message, data);
            }

            warning(functionName, message, data = null) {
                this._log(LogLevel.WARNING, functionName, message, data);
            }

            error(functionName, message, data = null) {
                this._log(LogLevel.ERROR, functionName, message, data);
            }
        }

        // Create loggers for different modules
        const cameraLogger = new Logger('Camera');
        const modelLogger = new Logger('Model');
        const inferenceLogger = new Logger('Inference');
        const renderLogger = new Logger('Render');
        const uiLogger = new Logger('UI');
        const mainLogger = new Logger('Main');

        // ============================================================================
        // APPLICATION STATE
        // ============================================================================
        let session = null;
        let autoMode = false;
        let isProcessing = false;
        let detections = [];
        let confidenceThreshold = 0.7;
        let animationFrameId = null;
        let trackingEnabled = false;
        let tracker = null;
        
        // Tracking parameters (default values)
        let trackingParams = {
            trackHighThresh: 0.6,
            trackLowThresh: 0.3,
            newTrackThresh: 0.7,
            matchThresh: 0.8,
            maxAge: 30,
            minHits: 3
        };

        const video = document.getElementById('video');
        const overlayCanvas = document.getElementById('overlayCanvas');
        const hiddenCanvas = document.getElementById('hiddenCanvas');
        const overlayCtx = overlayCanvas.getContext('2d');
        const hiddenCtx = hiddenCanvas.getContext('2d', { willReadFrequently: true });

        const statusText = document.getElementById('statusText');
        const inferenceTimeEl = document.getElementById('inferenceTime');
        const providerEl = document.getElementById('provider');
        const detectionTotalEl = document.getElementById('detectionTotal');
        const thresholdValueEl = document.getElementById('thresholdValue');
        const detectionCountEl = document.getElementById('detectionCount');

        const runOnceBtn = document.getElementById('runOnce');
        const autoModeBtn = document.getElementById('autoMode');
        const captureBtn = document.getElementById('capture');
        const downloadTrainingBtn = document.getElementById('downloadTraining');
        const includeOverlayCheckbox = document.getElementById('includeOverlay');
        const enableTrackingCheckbox = document.getElementById('enableTracking');
        const thresholdInput = document.getElementById('threshold');
        
        // Tracking parameter UI elements
        const trackingParamsPanel = document.getElementById('trackingParams');
        const trackHighThreshSlider = document.getElementById('trackHighThresh');
        const trackHighThreshValueEl = document.getElementById('trackHighThreshValue');
        const trackLowThreshSlider = document.getElementById('trackLowThresh');
        const trackLowThreshValueEl = document.getElementById('trackLowThreshValue');
        const newTrackThreshSlider = document.getElementById('newTrackThresh');
        const newTrackThreshValueEl = document.getElementById('newTrackThreshValue');
        const matchThreshSlider = document.getElementById('matchThresh');
        const matchThreshValueEl = document.getElementById('matchThreshValue');
        const maxAgeSlider = document.getElementById('maxAge');
        const maxAgeValueEl = document.getElementById('maxAgeValue');
        const minHitsSlider = document.getElementById('minHits');
        const minHitsValueEl = document.getElementById('minHitsValue');

        // ============================================================================
        // TRACKING UTILITIES
        // ============================================================================
        function initializeTracker() {
            tracker = new ByteTracker({
                trackHighThresh: trackingParams.trackHighThresh,
                trackLowThresh: trackingParams.trackLowThresh,
                newTrackThresh: trackingParams.newTrackThresh,
                matchThresh: trackingParams.matchThresh,
                maxAge: trackingParams.maxAge,
                minHits: trackingParams.minHits
            });
            uiLogger.info('initializeTracker', 'ByteTracker initialized with parameters', trackingParams);
        }

        // ============================================================================
        // CAMERA INITIALIZATION
        // ============================================================================
        async function initCamera() {
            cameraLogger.info('initCamera', 'Starting camera initialization');
            try {
                statusText.textContent = 'Requesting camera access...';
                cameraLogger.debug('initCamera', 'Requesting camera permissions with constraints', {
                    facingMode: 'environment',
                    width: 1920,
                    height: 1080
                });
                
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        facingMode: 'environment',
                        width: { ideal: 1920 },
                        height: { ideal: 1080 }
                    }
                });
                
                cameraLogger.info('initCamera', 'Camera access granted');
                video.srcObject = stream;
                
                video.onloadedmetadata = () => {
                    const videoInfo = {
                        clientWidth: video.clientWidth,
                        clientHeight: video.clientHeight,
                        videoWidth: video.videoWidth,
                        videoHeight: video.videoHeight
                    };
                    cameraLogger.info('initCamera', 'Video metadata loaded', videoInfo);
                    
                    overlayCanvas.width = video.clientWidth;
                    overlayCanvas.height = video.clientHeight;
                    statusText.textContent = 'Camera ready';
                    
                    cameraLogger.info('initCamera', 'Camera initialization complete');
                };
            } catch (error) {
                cameraLogger.error('initCamera', `Failed to initialize camera: ${error.message}`, error);
                statusText.textContent = `Camera error: ${error.message}`;
            }
        }

        // ============================================================================
        // MODEL LOADING
        // ============================================================================
        async function loadModel() {
            modelLogger.info('loadModel', 'Starting model loading');
            
            if (!window.ort) {
                modelLogger.error('loadModel', 'ONNX Runtime not available in window object');
                statusText.textContent = 'Error: ONNX Runtime not loaded';
                return;
            }

            modelLogger.debug('loadModel', `ONNX Runtime version: ${ort.env.versions.common}`);

            try {
                statusText.textContent = 'Loading model...';
                modelLogger.info('loadModel', 'Creating inference session with WebGPU (no fallback)');

                const startTime = performance.now();
                session = await ort.InferenceSession.create('/models/trading_card_detector.onnx', {
                    executionProviders: ['webgpu'],
                    graphOptimizationLevel: 'all'
                });

                const loadTime = performance.now() - startTime;
                modelLogger.info('loadModel', `Model loaded successfully in ${loadTime.toFixed(2)}ms`);
                
                // Log model details
                const modelInfo = {
                    inputNames: session.inputNames,
                    outputNames: session.outputNames,
                    inputTypes: session.inputNames.map(name => {
                        const input = session._model?.graph?.input?.find(i => i.name === name);
                        return input?.type?.tensorType?.elemType || 'unknown';
                    })
                };
                modelLogger.debug('loadModel', 'Model metadata', modelInfo);
                
                statusText.textContent = 'Model ready - Click Start Auto or Run Once';
                providerEl.textContent = 'WebGPU';
                
                runOnceBtn.disabled = false;
                autoModeBtn.disabled = false;
                
                modelLogger.info('loadModel', 'Model initialization complete');
            } catch (error) {
                modelLogger.error('loadModel', `Failed to load model: ${error.message}`, {
                    error: error,
                    stack: error.stack
                });
                statusText.textContent = `Model load error: ${error.message}`;
            }
        }

        // ============================================================================
        // IMAGE PREPROCESSING
        // ============================================================================
        function preprocessImage(imageData) {
            inferenceLogger.debug('preprocessImage', `Starting preprocessing of ${imageData.width}x${imageData.height} image`);
            
            const { width, height } = imageData;
            const targetSize = 1088;

            const scale = Math.min(targetSize / width, targetSize / height);
            const newW = Math.round(width * scale);
            const newH = Math.round(height * scale);
            const padX = Math.floor((targetSize - newW) / 2);
            const padY = Math.floor((targetSize - newH) / 2);

            inferenceLogger.debug('preprocessImage', 'Scaling parameters', {
                originalSize: `${width}x${height}`,
                targetSize: targetSize,
                scale: scale.toFixed(3),
                scaledSize: `${newW}x${newH}`,
                padding: `${padX}x${padY}`
            });

            // Create source canvas from ImageData
            const srcCanvas = document.createElement('canvas');
            const srcCtx = srcCanvas.getContext('2d');
            srcCanvas.width = width;
            srcCanvas.height = height;
            srcCtx.putImageData(imageData, 0, 0);

            // Create target canvas with padding
            const dstCanvas = document.createElement('canvas');
            const dstCtx = dstCanvas.getContext('2d');
            dstCanvas.width = targetSize;
            dstCanvas.height = targetSize;

            // Fill with gray padding
            dstCtx.fillStyle = '#808080';
            dstCtx.fillRect(0, 0, targetSize, targetSize);
            dstCtx.drawImage(srcCanvas, 0, 0, width, height, padX, padY, newW, newH);

            // Convert to tensor
            const resized = dstCtx.getImageData(0, 0, targetSize, targetSize);
            const pixels = resized.data;
            const tensorData = new Float32Array(1 * 3 * targetSize * targetSize);
            const pixelCount = targetSize * targetSize;

            inferenceLogger.debug('preprocessImage', 'Converting to tensor (CHW format)');
            for (let i = 0; i < pixelCount; i++) {
                const p = i * 4;
                tensorData[i] = pixels[p] / 255.0;
                tensorData[i + pixelCount] = pixels[p + 1] / 255.0;
                tensorData[i + 2 * pixelCount] = pixels[p + 2] / 255.0;
            }

            const tensor = new ort.Tensor('float32', tensorData, [1, 3, targetSize, targetSize]);
            inferenceLogger.debug('preprocessImage', `Tensor created: ${tensor.dims.join('x')}, type: ${tensor.type}`);
            
            return tensor;
        }

        // ============================================================================
        // INFERENCE
        // ============================================================================
        async function runInference() {
            if (!session) {
                inferenceLogger.warning('runInference', 'No session available, skipping inference');
                return;
            }
            
            if (isProcessing) {
                inferenceLogger.debug('runInference', 'Already processing, skipping this frame');
                return;
            }

            inferenceLogger.info('runInference', 'Starting inference');

            try {
                isProcessing = true;

                // Capture video frame
                hiddenCanvas.width = video.videoWidth;
                hiddenCanvas.height = video.videoHeight;
                hiddenCtx.drawImage(video, 0, 0);
                inferenceLogger.debug('runInference', `Captured frame: ${video.videoWidth}x${video.videoHeight}`);

                const imageData = hiddenCtx.getImageData(0, 0, hiddenCanvas.width, hiddenCanvas.height);
                const inputTensor = preprocessImage(imageData);

                // Run model inference
                inferenceLogger.debug('runInference', 'Running model with input', {
                    inputName: session.inputNames[0],
                    inputShape: inputTensor.dims.join('x')
                });
                
                const inferenceStart = performance.now();
                const results = await session.run({
                    [session.inputNames[0]]: inputTensor
                });
                const inferenceMs = performance.now() - inferenceStart;

                inferenceLogger.info('runInference', `Inference completed in ${inferenceMs.toFixed(1)}ms`);
                inferenceTimeEl.textContent = `${inferenceMs.toFixed(0)}ms`;
                providerEl.textContent = 'WebGPU';

                // Validate outputs
                inferenceLogger.debug('runInference', 'Model outputs', {
                    expectedOutputs: session.outputNames,
                    actualOutputs: Object.keys(results),
                    outputCount: session.outputNames.length
                });

                // Log detailed output information
                session.outputNames.forEach((name, idx) => {
                    if (results[name]) {
                        inferenceLogger.debug('runInference', `Output ${idx}: ${name}`, {
                            shape: results[name].dims.join('x'),
                            type: results[name].type,
                            dataLength: results[name].data.length,
                            firstFewValues: Array.from(results[name].data.slice(0, 10))
                        });
                    }
                });

                // Parse output based on structure
                const output = results[session.outputNames[0]];
                const outputData = output.data;
                const outputShape = output.dims;
                
                inferenceLogger.debug('runInference', 'Parsing output', {
                    shape: outputShape.join('x'),
                    format: 'OBB (Oriented Bounding Boxes)',
                    valuesPerDetection: outputShape[2]
                });

                // Parse OBB format: [batch, num_detections, 7]
                // Each detection: [x_center, y_center, width, height, confidence, class_id, angle]
                const numDetections = outputShape[1];
                const valuesPerDetection = outputShape[2];
                
                if (valuesPerDetection !== 7) {
                    inferenceLogger.warning('runInference', `Expected 7 values per detection, got ${valuesPerDetection}`);
                }

                // Process detections
                detections = [];
                const minConfidence = 0.3;
                
                for (let i = 0; i < numDetections; i++) {
                    const offset = i * valuesPerDetection;
                    const x = outputData[offset];
                    const y = outputData[offset + 1];
                    const w = outputData[offset + 2];
                    const h = outputData[offset + 3];
                    const confidence = outputData[offset + 4];
                    const classId = outputData[offset + 5];
                    const angle = outputData[offset + 6];
                    
                    if (confidence >= minConfidence) {
                        // Normalize coordinates (assuming they're in pixel space of 1088x1088)
                        const normalizedX = x / 1088;
                        const normalizedY = y / 1088;
                        const normalizedW = w / 1088;
                        const normalizedH = h / 1088;
                        
                        detections.push({
                            x: normalizedX,
                            y: normalizedY,
                            width: normalizedW,
                            height: normalizedH,
                            confidence: confidence,
                            classId: classId,
                            angle: angle
                        });
                    }
                }

                inferenceLogger.info('runInference', `Found ${detections.length} detections (threshold: 0.3)`);
                
                if (detections.length > 0) {
                    const confidences = detections.map(d => d.confidence.toFixed(3));
                    inferenceLogger.debug('runInference', 'Detection confidences', { confidences });
                }

                // Apply object tracking if enabled
                if (trackingEnabled && tracker) {
                    inferenceLogger.info('runInference', 'Applying ByteTrack object tracking');
                    const trackedDetections = tracker.update(detections);
                    inferenceLogger.info('runInference', `Tracking: ${detections.length} raw -> ${trackedDetections.length} tracked`);
                    detections = trackedDetections;
                }

                drawDetections();
                updateStats();

            } catch (error) {
                inferenceLogger.error('runInference', `Inference failed: ${error.message}`, {
                    error: error,
                    stack: error.stack
                });
                statusText.textContent = `Error: ${error.message}`;
            } finally {
                isProcessing = false;
                inferenceLogger.debug('runInference', 'Inference complete, released processing lock');
            }
        }

        // ============================================================================
        // RENDERING
        // ============================================================================
        function drawDetections() {
            renderLogger.debug('drawDetections', `Drawing ${detections.length} detections`);
            
            overlayCanvas.width = video.clientWidth;
            overlayCanvas.height = video.clientHeight;
            overlayCtx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);

            const filtered = detections.filter(d => d.confidence >= confidenceThreshold);
            renderLogger.debug('drawDetections', `${filtered.length} detections pass threshold ${confidenceThreshold}`);

            filtered.forEach((det, idx) => {
                // Convert normalized coordinates to canvas pixels
                const centerX = det.x * overlayCanvas.width;
                const centerY = det.y * overlayCanvas.height;
                const w = det.width * overlayCanvas.width;
                const h = det.height * overlayCanvas.height;
                const angle = det.angle || 0;

                overlayCtx.save();
                
                // Move to center of box and rotate
                overlayCtx.translate(centerX, centerY);
                overlayCtx.rotate(angle);
                
                // Draw rotated rectangle (centered at origin after translate)
                overlayCtx.strokeStyle = '#00ff00';
                overlayCtx.lineWidth = 3;
                overlayCtx.strokeRect(-w/2, -h/2, w, h);
                
                // Draw confidence label (unrotated for readability)
                overlayCtx.rotate(-angle);
                overlayCtx.fillStyle = '#00ff00';
                overlayCtx.font = '16px monospace';
                
                // Show track ID if tracking is enabled, otherwise just confidence
                let label;
                if (trackingEnabled && det.trackId !== undefined) {
                    label = `ID:${det.trackId} ${(det.confidence * 100).toFixed(0)}%`;
                } else {
                    label = `${(det.confidence * 100).toFixed(0)}%`;
                }
                
                overlayCtx.fillText(label, -w/2, -h/2 - 5);
                
                overlayCtx.restore();
            });
            
            if (filtered.length > 0) {
                renderLogger.debug('drawDetections', `Rendered ${filtered.length} oriented bounding boxes`);
            }
        }

        // ============================================================================
        // UI UPDATES
        // ============================================================================
        function updateStats() {
            const filtered = detections.filter(d => d.confidence >= confidenceThreshold);
            detectionTotalEl.textContent = detections.length;
            detectionCountEl.textContent = `${filtered.length} / ${detections.length} cards shown`;
            captureBtn.textContent = `Capture (${filtered.length})`;
            captureBtn.disabled = filtered.length === 0;
            downloadTrainingBtn.disabled = detections.length === 0;
            
            uiLogger.debug('updateStats', `Stats updated: ${filtered.length}/${detections.length} shown`);
        }

        // ============================================================================
        // AUTO MODE LOOP
        // ============================================================================
        function autoModeLoop() {
            if (!autoMode || isProcessing) {
                animationFrameId = requestAnimationFrame(autoModeLoop);
                return;
            }
            
            runInference().then(() => {
                if (autoMode) {
                    animationFrameId = requestAnimationFrame(autoModeLoop);
                }
            });
        }

        // ============================================================================
        // TRAINING DATA EXPORT
        // ============================================================================
        
        /**
         * Convert OBB (center, width, height, angle) to 4 corner points
         * Returns normalized coordinates in YOLO OBB format
         */
        function obbToCorners(detection) {
            const { x, y, width, height, angle } = detection;
            
            // Half dimensions
            const hw = width / 2;
            const hh = height / 2;
            
            // Compute corners relative to center (before rotation)
            // Top-left, top-right, bottom-right, bottom-left
            const corners = [
                [-hw, -hh],
                [hw, -hh],
                [hw, hh],
                [-hw, hh]
            ];
            
            // Rotate corners around center
            const cos = Math.cos(angle);
            const sin = Math.sin(angle);
            
            const rotatedCorners = corners.map(([cx, cy]) => {
                const rx = cx * cos - cy * sin;
                const ry = cx * sin + cy * cos;
                return [x + rx, y + ry];
            });
            
            return rotatedCorners;
        }
        
        /**
         * Generate YOLO OBB format label file content
         */
        function generateLabelFile(detections) {
            const lines = detections.map(det => {
                const corners = obbToCorners(det);
                const classId = Math.round(det.classId);
                
                // Format: class_id x1 y1 x2 y2 x3 y3 x4 y4
                const coords = corners.map(([x, y]) => 
                    `${x.toFixed(6)} ${y.toFixed(6)}`
                ).join(' ');
                
                return `${classId} ${coords}`;
            }).join('\n');
            
            return lines + '\n';
        }
        
        /**
         * Trigger file download
         */
        function downloadFile(content, filename, mimeType) {
            const blob = new Blob([content], { type: mimeType });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = filename;
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            URL.revokeObjectURL(url);
        }
        
        /**
         * Draw bounding boxes on a canvas for visualization
         * Note: Canvas dimensions should already be set by caller
         */
        function drawOverlayOnCanvas(ctx, imageWidth, imageHeight, detectionsArray) {
            detectionsArray.forEach((det) => {
                // Convert normalized coordinates to canvas pixels
                const centerX = det.x * imageWidth;
                const centerY = det.y * imageHeight;
                const w = det.width * imageWidth;
                const h = det.height * imageHeight;
                const angle = det.angle || 0;

                ctx.save();
                
                // Move to center of box and rotate
                ctx.translate(centerX, centerY);
                ctx.rotate(angle);
                
                // Draw rotated rectangle (centered at origin after translate)
                ctx.strokeStyle = '#00ff00';
                ctx.lineWidth = 3;
                ctx.strokeRect(-w/2, -h/2, w, h);
                
                // Draw confidence label (unrotated for readability)
                ctx.rotate(-angle);
                ctx.fillStyle = '#00ff00';
                ctx.font = '20px monospace';
                ctx.strokeStyle = '#000000';
                ctx.lineWidth = 4;
                
                // Show track ID if available, otherwise just confidence
                let label;
                if (det.trackId !== undefined) {
                    label = `ID:${det.trackId} ${(det.confidence * 100).toFixed(0)}%`;
                } else {
                    label = `${(det.confidence * 100).toFixed(0)}%`;
                }
                
                // Draw text with black outline for visibility
                ctx.strokeText(label, -w/2, -h/2 - 8);
                ctx.fillText(label, -w/2, -h/2 - 8);
                
                ctx.restore();
            });
        }

        /**
         * Download current frame as training data
         */
        async function downloadTrainingData() {
            if (detections.length === 0) {
                uiLogger.warning('downloadTrainingData', 'No detections to export');
                alert('No detections available. Run inference first.');
                return;
            }
            
            // Filter detections by confidence threshold
            const filteredDetections = detections.filter(d => d.confidence >= confidenceThreshold);
            
            if (filteredDetections.length === 0) {
                uiLogger.warning('downloadTrainingData', 'No detections pass confidence threshold');
                alert(`No detections pass the ${(confidenceThreshold * 100).toFixed(0)}% confidence threshold. Lower the threshold or run inference again.`);
                return;
            }
            
            try {
                uiLogger.info('downloadTrainingData', `Exporting ${filteredDetections.length} detections as training data (threshold: ${confidenceThreshold})`);
                
                // Generate timestamp-based filename
                const timestamp = new Date().toISOString().replace(/[:.]/g, '-').split('T').join('_').slice(0, -5);
                const baseFilename = `training_${timestamp}`;
                
                // Capture current frame from video
                hiddenCanvas.width = video.videoWidth;
                hiddenCanvas.height = video.videoHeight;
                hiddenCtx.drawImage(video, 0, 0);
                
                // Download original image as JPG
                hiddenCanvas.toBlob((blob) => {
                    const url = URL.createObjectURL(blob);
                    const a = document.createElement('a');
                    a.href = url;
                    a.download = `${baseFilename}.jpg`;
                    document.body.appendChild(a);
                    a.click();
                    document.body.removeChild(a);
                    URL.revokeObjectURL(url);
                    
                    uiLogger.info('downloadTrainingData', `Downloaded image: ${baseFilename}.jpg`);
                }, 'image/jpeg', 0.95);
                
                // Download overlay visualization if checkbox is checked
                if (includeOverlayCheckbox.checked) {
                    uiLogger.info('downloadTrainingData', 'Creating overlay visualization');
                    
                    // Create a temporary canvas for the overlay
                    const overlayVisCanvas = document.createElement('canvas');
                    const overlayVisCtx = overlayVisCanvas.getContext('2d');
                    
                    // Set canvas size FIRST (this clears the canvas)
                    overlayVisCanvas.width = video.videoWidth;
                    overlayVisCanvas.height = video.videoHeight;
                    
                    // Draw the captured frame from hiddenCanvas
                    overlayVisCtx.drawImage(hiddenCanvas, 0, 0);
                    
                    // Draw filtered bounding boxes on top (don't resize canvas again!)
                    drawOverlayOnCanvas(overlayVisCtx, video.videoWidth, video.videoHeight, filteredDetections);
                    
                    // Download overlay image
                    overlayVisCanvas.toBlob((blob) => {
                        const url = URL.createObjectURL(blob);
                        const a = document.createElement('a');
                        a.href = url;
                        a.download = `${baseFilename}_overlay.jpg`;
                        document.body.appendChild(a);
                        a.click();
                        document.body.removeChild(a);
                        URL.revokeObjectURL(url);
                        
                        uiLogger.info('downloadTrainingData', `Downloaded overlay: ${baseFilename}_overlay.jpg`);
                    }, 'image/jpeg', 0.95);
                }
                
                // Generate and download label file (filtered detections only)
                const labelContent = generateLabelFile(filteredDetections);
                downloadFile(labelContent, `${baseFilename}.txt`, 'text/plain');
                
                uiLogger.info('downloadTrainingData', `Downloaded labels: ${baseFilename}.txt`);
                uiLogger.debug('downloadTrainingData', 'Label content', { labelContent });
                
                const filesDownloaded = includeOverlayCheckbox.checked ? 3 : 2;
                statusText.textContent = `Training data downloaded: ${filesDownloaded} files, ${filteredDetections.length} detections`;
                setTimeout(() => {
                    statusText.textContent = 'Model ready - Click Start Auto or Run Once';
                }, 3000);
                
            } catch (error) {
                uiLogger.error('downloadTrainingData', `Failed to download training data: ${error.message}`, error);
                alert(`Error downloading training data: ${error.message}`);
            }
        }

        // ============================================================================
        // EVENT HANDLERS
        // ============================================================================
        runOnceBtn.addEventListener('click', () => {
            uiLogger.info('runOnceBtn.click', 'User clicked Run Once');
            runInference();
        });

        autoModeBtn.addEventListener('click', () => {
            autoMode = !autoMode;
            if (autoMode) {
                uiLogger.info('autoModeBtn.click', 'Starting auto mode');
                autoModeBtn.textContent = 'Stop Auto';
                autoModeBtn.classList.add('stop');
                runOnceBtn.disabled = true;
                autoModeLoop();
            } else {
                uiLogger.info('autoModeBtn.click', 'Stopping auto mode');
                autoModeBtn.textContent = 'Start Auto';
                autoModeBtn.classList.remove('stop');
                runOnceBtn.disabled = false;
                if (animationFrameId) {
                    cancelAnimationFrame(animationFrameId);
                    animationFrameId = null;
                }
            }
        });

        captureBtn.addEventListener('click', () => {
            const filtered = detections.filter(d => d.confidence >= confidenceThreshold);
            uiLogger.info('captureBtn.click', `User clicked capture with ${filtered.length} detections`);
            alert(`Would capture ${filtered.length} cards (not implemented in test page)`);
        });

        downloadTrainingBtn.addEventListener('click', () => {
            uiLogger.info('downloadTrainingBtn.click', 'User clicked Download Training Data');
            downloadTrainingData();
        });

        thresholdInput.addEventListener('input', (e) => {
            const oldThreshold = confidenceThreshold;
            confidenceThreshold = parseFloat(e.target.value);
            uiLogger.debug('thresholdInput.input', `Threshold changed: ${oldThreshold.toFixed(2)} -> ${confidenceThreshold.toFixed(2)}`);
            
            thresholdValueEl.textContent = `${(confidenceThreshold * 100).toFixed(0)}%`;
            drawDetections();
            updateStats();
        });

        enableTrackingCheckbox.addEventListener('change', (e) => {
            trackingEnabled = e.target.checked;
            
            if (trackingEnabled) {
                uiLogger.info('enableTrackingCheckbox.change', 'Object tracking enabled');
                
                // Initialize tracker with current parameters
                initializeTracker();
                
                // Show tracking parameters panel
                trackingParamsPanel.classList.add('visible');
                
                statusText.textContent = 'Object tracking enabled - tracks will stabilize over time';
                setTimeout(() => {
                    statusText.textContent = 'Model ready - Click Start Auto or Run Once';
                }, 2000);
            } else {
                uiLogger.info('enableTrackingCheckbox.change', 'Object tracking disabled - showing raw detections');
                tracker = null;
                
                // Hide tracking parameters panel
                trackingParamsPanel.classList.remove('visible');
                
                statusText.textContent = 'Object tracking disabled - showing raw detections';
                setTimeout(() => {
                    statusText.textContent = 'Model ready - Click Start Auto or Run Once';
                }, 2000);
            }
            
            // Redraw current detections with new tracking state
            drawDetections();
        });

        // Tracking parameter sliders
        trackHighThreshSlider.addEventListener('input', (e) => {
            trackingParams.trackHighThresh = parseFloat(e.target.value);
            trackHighThreshValueEl.textContent = `${(trackingParams.trackHighThresh * 100).toFixed(0)}%`;
            
            if (trackingEnabled && tracker) {
                uiLogger.info('trackHighThreshSlider.input', `Reinitializing tracker with trackHighThresh=${trackingParams.trackHighThresh}`);
                initializeTracker();
            }
        });

        trackLowThreshSlider.addEventListener('input', (e) => {
            trackingParams.trackLowThresh = parseFloat(e.target.value);
            trackLowThreshValueEl.textContent = `${(trackingParams.trackLowThresh * 100).toFixed(0)}%`;
            
            if (trackingEnabled && tracker) {
                uiLogger.info('trackLowThreshSlider.input', `Reinitializing tracker with trackLowThresh=${trackingParams.trackLowThresh}`);
                initializeTracker();
            }
        });

        newTrackThreshSlider.addEventListener('input', (e) => {
            trackingParams.newTrackThresh = parseFloat(e.target.value);
            newTrackThreshValueEl.textContent = `${(trackingParams.newTrackThresh * 100).toFixed(0)}%`;
            
            if (trackingEnabled && tracker) {
                uiLogger.info('newTrackThreshSlider.input', `Reinitializing tracker with newTrackThresh=${trackingParams.newTrackThresh}`);
                initializeTracker();
            }
        });

        matchThreshSlider.addEventListener('input', (e) => {
            trackingParams.matchThresh = parseFloat(e.target.value);
            matchThreshValueEl.textContent = trackingParams.matchThresh.toFixed(2);
            
            if (trackingEnabled && tracker) {
                uiLogger.info('matchThreshSlider.input', `Reinitializing tracker with matchThresh=${trackingParams.matchThresh}`);
                initializeTracker();
            }
        });

        maxAgeSlider.addEventListener('input', (e) => {
            trackingParams.maxAge = parseInt(e.target.value);
            maxAgeValueEl.textContent = trackingParams.maxAge;
            
            if (trackingEnabled && tracker) {
                uiLogger.info('maxAgeSlider.input', `Reinitializing tracker with maxAge=${trackingParams.maxAge}`);
                initializeTracker();
            }
        });

        minHitsSlider.addEventListener('input', (e) => {
            trackingParams.minHits = parseInt(e.target.value);
            minHitsValueEl.textContent = trackingParams.minHits;
            
            if (trackingEnabled && tracker) {
                uiLogger.info('minHitsSlider.input', `Reinitializing tracker with minHits=${trackingParams.minHits}`);
                initializeTracker();
            }
        });

        // ============================================================================
        // INITIALIZATION
        // ============================================================================
        mainLogger.info('init', 'Application starting');
        mainLogger.debug('init', 'User agent', { userAgent: navigator.userAgent });
        mainLogger.debug('init', 'WebGPU support', { 
            hasGPU: 'gpu' in navigator,
            hasWebGPU: typeof navigator.gpu !== 'undefined'
        });
        
        initCamera();
        loadModel();
    </script>
</body>
</html>

